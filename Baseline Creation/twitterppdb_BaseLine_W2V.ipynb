{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Number: 42\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code is generating a Word2Vec-based baseline for the Twitterppdb dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train= pd.read_csv(\"train/a.toks\",delimiter='\\t', header=None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how the metaphors we use to describe discovery...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how the metaphors we use to describe discovery...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how the metaphors we use to describe discovery...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how the metaphors we use to describe discovery...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>how the metaphors we use to describe discovery...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42195</th>\n",
       "      <td>we asked 15 families about the thanksgiving di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42196</th>\n",
       "      <td>we asked 15 families about the thanksgiving di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42197</th>\n",
       "      <td>we asked 15 families about the thanksgiving di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42198</th>\n",
       "      <td>we asked 15 families about the thanksgiving di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42199</th>\n",
       "      <td>we asked 15 families about the thanksgiving di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42200 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0\n",
       "0      how the metaphors we use to describe discovery...\n",
       "1      how the metaphors we use to describe discovery...\n",
       "2      how the metaphors we use to describe discovery...\n",
       "3      how the metaphors we use to describe discovery...\n",
       "4      how the metaphors we use to describe discovery...\n",
       "...                                                  ...\n",
       "42195  we asked 15 families about the thanksgiving di...\n",
       "42196  we asked 15 families about the thanksgiving di...\n",
       "42197  we asked 15 families about the thanksgiving di...\n",
       "42198  we asked 15 families about the thanksgiving di...\n",
       "42199  we asked 15 families about the thanksgiving di...\n",
       "\n",
       "[42200 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source=df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target= pd.read_csv(\"train/b.toks\",delimiter='\\t', header=None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>light bulbs or seeds ? how metaphors for ideas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great description of a nasty catch-22 facing w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academic reading &amp; amp ; writing , read the ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>big ideas take enormous effort and how we talk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>how we talk about discovery matters in #stem f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42195</th>\n",
       "      <td>so amazing to see @pastrydiane and her family ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42196</th>\n",
       "      <td>15 recipes from americans of different backgro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42197</th>\n",
       "      <td>the american thanksgiving 15 families discuss ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42198</th>\n",
       "      <td>what a beautiful piece from the @nytimes on th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42199</th>\n",
       "      <td>the times asked 15 american families to talk a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42200 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0\n",
       "0      light bulbs or seeds ? how metaphors for ideas...\n",
       "1      great description of a nasty catch-22 facing w...\n",
       "2      academic reading & amp ; writing , read the ar...\n",
       "3      big ideas take enormous effort and how we talk...\n",
       "4      how we talk about discovery matters in #stem f...\n",
       "...                                                  ...\n",
       "42195  so amazing to see @pastrydiane and her family ...\n",
       "42196  15 recipes from americans of different backgro...\n",
       "42197  the american thanksgiving 15 families discuss ...\n",
       "42198  what a beautiful piece from the @nytimes on th...\n",
       "42199  the times asked 15 american families to talk a...\n",
       "\n",
       "[42200 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=pd.read_csv(\"train/sim.txt\",delimiter='\\t', header=None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42195</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42196</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42197</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42198</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42199</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42200 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "...   ..\n",
       "42195  0\n",
       "42196  1\n",
       "42197  1\n",
       "42198  0\n",
       "42199  1\n",
       "\n",
       "[42200 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train[0]\n",
    "X_train=source[0]+\" \"+target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "42195    0\n",
       "42196    1\n",
       "42197    1\n",
       "42198    0\n",
       "42199    1\n",
       "Name: 0, Length: 42200, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        how the metaphors we use to describe discovery...\n",
       "1        how the metaphors we use to describe discovery...\n",
       "2        how the metaphors we use to describe discovery...\n",
       "3        how the metaphors we use to describe discovery...\n",
       "4        how the metaphors we use to describe discovery...\n",
       "                               ...                        \n",
       "42195    we asked 15 families about the thanksgiving di...\n",
       "42196    we asked 15 families about the thanksgiving di...\n",
       "42197    we asked 15 families about the thanksgiving di...\n",
       "42198    we asked 15 families about the thanksgiving di...\n",
       "42199    we asked 15 families about the thanksgiving di...\n",
       "Name: 0, Length: 42200, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_source=pd.read_csv(\"test/a.toks\",delimiter='\\t', header=None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how an unverified but explosive dossier became...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how an unverified but explosive dossier became...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how an unverified but explosive dossier became...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how an unverified but explosive dossier became...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>how an unverified but explosive dossier became...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9319</th>\n",
       "      <td>finalists for the national book critics circle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9320</th>\n",
       "      <td>finalists for the national book critics circle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9321</th>\n",
       "      <td>finalists for the national book critics circle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9322</th>\n",
       "      <td>finalists for the national book critics circle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9323</th>\n",
       "      <td>finalists for the national book critics circle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9324 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "0     how an unverified but explosive dossier became...\n",
       "1     how an unverified but explosive dossier became...\n",
       "2     how an unverified but explosive dossier became...\n",
       "3     how an unverified but explosive dossier became...\n",
       "4     how an unverified but explosive dossier became...\n",
       "...                                                 ...\n",
       "9319  finalists for the national book critics circle...\n",
       "9320  finalists for the national book critics circle...\n",
       "9321  finalists for the national book critics circle...\n",
       "9322  finalists for the national book critics circle...\n",
       "9323  finalists for the national book critics circle...\n",
       "\n",
       "[9324 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target=pd.read_csv(\"test/b.toks\",delimiter='\\t', header=None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how a sensational , unverified dossier became ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dossier donald trump don't forget , dnc hacked...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a wealthy republican donor who strongly oppose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how an unverified dossier became a crisis for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>outstanding piece puts russian rumors re trump...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9319</th>\n",
       "      <td>a few american friends complain i am being too...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9320</th>\n",
       "      <td>yaa gyasi awarded john leonard prize for homeg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9321</th>\n",
       "      <td>am i alone here ? by @peter_orner has been nam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9322</th>\n",
       "      <td>congrats to alice kaplan @yale , finalist for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9323</th>\n",
       "      <td>jane mayer and ann patchett are also among the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9324 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "0     how a sensational , unverified dossier became ...\n",
       "1     dossier donald trump don't forget , dnc hacked...\n",
       "2     a wealthy republican donor who strongly oppose...\n",
       "3     how an unverified dossier became a crisis for ...\n",
       "4     outstanding piece puts russian rumors re trump...\n",
       "...                                                 ...\n",
       "9319  a few american friends complain i am being too...\n",
       "9320  yaa gyasi awarded john leonard prize for homeg...\n",
       "9321  am i alone here ? by @peter_orner has been nam...\n",
       "9322  congrats to alice kaplan @yale , finalist for ...\n",
       "9323  jane mayer and ann patchett are also among the...\n",
       "\n",
       "[9324 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=pd.read_csv(\"test/sim.txt\",delimiter='\\t', header=None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9319</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9320</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9321</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9322</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9323</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9324 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0     1\n",
       "1     0\n",
       "2     0\n",
       "3     1\n",
       "4     0\n",
       "...  ..\n",
       "9319  0\n",
       "9320  0\n",
       "9321  0\n",
       "9322  1\n",
       "9323  0\n",
       "\n",
       "[9324 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=y_test[0]\n",
    "X_test=test_source[0]+\" \"+test_target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       0\n",
       "3       1\n",
       "4       0\n",
       "       ..\n",
       "9319    0\n",
       "9320    0\n",
       "9321    0\n",
       "9322    1\n",
       "9323    0\n",
       "Name: 0, Length: 9324, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       how an unverified but explosive dossier became...\n",
       "1       how an unverified but explosive dossier became...\n",
       "2       how an unverified but explosive dossier became...\n",
       "3       how an unverified but explosive dossier became...\n",
       "4       how an unverified but explosive dossier became...\n",
       "                              ...                        \n",
       "9319    finalists for the national book critics circle...\n",
       "9320    finalists for the national book critics circle...\n",
       "9321    finalists for the national book critics circle...\n",
       "9322    finalists for the national book critics circle...\n",
       "9323    finalists for the national book critics circle...\n",
       "Name: 0, Length: 9324, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "word_vectors = api.load('word2vec-google-news-300')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_embedding(doc):\n",
    "    words = doc.lower().split()\n",
    "    return word_vectors.get_mean_vector(words)\n",
    "\n",
    "source[0] = source[0].apply(lambda x: np.array(get_doc_embedding(x)))\n",
    "target[0] = target[0].apply(lambda x: np.array(get_doc_embedding(x)))\n",
    "x1 = np.stack(source[0].values)\n",
    "x2 = np.stack(target[0].values)\n",
    "X_train = np.hstack((x1, x2))\n",
    "y_train = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_embedding(doc):\n",
    "    words = doc.lower().split()\n",
    "    return word_vectors.get_mean_vector(words)\n",
    "\n",
    "test_source[0] = test_source[0].apply(lambda x: np.array(get_doc_embedding(x)))\n",
    "test_target[0] = test_target[0].apply(lambda x: np.array(get_doc_embedding(x)))\n",
    "x1 = np.stack(test_source[0].values)\n",
    "x2 = np.stack(test_target[0].values)\n",
    "X_test = np.hstack((x1, x2))\n",
    "y_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       0\n",
       "3       1\n",
       "4       0\n",
       "       ..\n",
       "9319    0\n",
       "9320    0\n",
       "9321    0\n",
       "9322    1\n",
       "9323    0\n",
       "Name: 0, Length: 9324, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03670343,  0.02582751,  0.01965243, ..., -0.05367235,\n",
       "        -0.01222366,  0.02762284],\n",
       "       [ 0.03670343,  0.02582751,  0.01965243, ..., -0.07480688,\n",
       "        -0.00891178,  0.02215355],\n",
       "       [ 0.03670343,  0.02582751,  0.01965243, ...,  0.00563173,\n",
       "         0.01055616, -0.02060932],\n",
       "       ...,\n",
       "       [-0.03073055,  0.0249352 , -0.00603749, ..., -0.00140599,\n",
       "        -0.01004266, -0.00150803],\n",
       "       [-0.03073055,  0.0249352 , -0.00603749, ..., -0.01530992,\n",
       "        -0.00759629,  0.01791251],\n",
       "       [-0.03073055,  0.0249352 , -0.00603749, ..., -0.01159143,\n",
       "         0.00496262, -0.01280443]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03393119,  0.03113483,  0.03692422, ..., -0.01278995,\n",
       "         0.01777831,  0.01067224],\n",
       "       [ 0.03393119,  0.03113483,  0.03692422, ..., -0.03568024,\n",
       "         0.0147134 ,  0.01203516],\n",
       "       [ 0.03393119,  0.03113483,  0.03692422, ..., -0.00050231,\n",
       "        -0.02430289,  0.00676973],\n",
       "       ...,\n",
       "       [ 0.01252555,  0.02558967,  0.03097087, ..., -0.01876852,\n",
       "         0.04856499, -0.02145283],\n",
       "       [ 0.01252555,  0.02558967,  0.03097087, ..., -0.02501415,\n",
       "         0.00019243, -0.02545443],\n",
       "       [ 0.01252555,  0.02558967,  0.03097087, ..., -0.00821432,\n",
       "         0.03213881, -0.01703839]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "42195    0\n",
       "42196    1\n",
       "42197    1\n",
       "42198    0\n",
       "42199    1\n",
       "Name: 0, Length: 42200, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.3701141473538568\n",
      "Precision: 0.4995331465919701\n",
      "Recall: 0.29395604395604397\n",
      "Accuracy: 0.8046975546975547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Darsh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier:\n",
      "Precision: 0.3098656785548865\n",
      "Recall: 0.3675824175824176\n",
      "F1-Score: 0.33626539331490324\n",
      "Accuracy: 0.7167524667524667\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "y_pred_dt = dt_classifier.predict(X_test)\n",
    "print(\"Decision Tree Classifier:\")\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_dt))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_dt))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred_dt))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "Precision: 0.6516129032258065\n",
      "Recall: 0.11098901098901098\n",
      "F1-Score: 0.1896713615023474\n",
      "Accuracy: 0.8148863148863149\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Initialize the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "print(\"Random Forest Classifier:\")\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_rf))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_rf))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred_rf))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier:\n",
      "Precision: 0.4125662376987131\n",
      "Recall: 0.29945054945054944\n",
      "F1-Score: 0.34702324100604903\n",
      "Accuracy: 0.78003003003003\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# # Initialize the AdaBoost Classifier\n",
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Initialize the AdaBoost Classifier\n",
    "ada_classifier = AdaBoostClassifier(learning_rate=1, n_estimators=100)\n",
    "\n",
    "ada_classifier.fit(X_train, y_train)\n",
    "y_pred_ada = ada_classifier.predict(X_test)\n",
    "print(\"AdaBoost Classifier:\")\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_ada))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_ada))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred_ada))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_ada))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier:\n",
      "Precision: 0.5372829417773238\n",
      "Recall: 0.578021978021978\n",
      "F1-Score: 0.5569084171519323\n",
      "Accuracy: 0.8204633204633205\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# Initialize the Gradient Boosting Classifier\n",
    "gb_classifier = GradientBoostingClassifier(learning_rate=1, n_estimators=100)\n",
    "\n",
    "# Train the model\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "y_pred_gb = gb_classifier.predict(X_test)\n",
    "print(\"Gradient Boosting Classifier:\")\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_gb))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_gb))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred_gb))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_gb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Classifier:\n",
      "Precision: 0.6767676767676768\n",
      "Recall: 0.07362637362637363\n",
      "F1-Score: 0.13280475718533202\n",
      "Accuracy: 0.8123123123123123\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "# Initialize the SGD Classifier\n",
    "sgd_classifier = SGDClassifier()\n",
    "\n",
    "sgd_classifier.fit(X_train, y_train)\n",
    "y_pred_sgd = sgd_classifier.predict(X_test)\n",
    "print(\"SGD Classifier:\")\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_sgd))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_sgd))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred_sgd))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_sgd))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Darsh\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC:\n",
      "Precision: 0.4704370179948586\n",
      "Recall: 0.30164835164835163\n",
      "F1-Score: 0.36759290257783733\n",
      "Accuracy: 0.7974045474045474\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "# Initialize the LinearSVC\n",
    "linear_svc = LinearSVC(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "linear_svc.fit(X_train, y_train)\n",
    "y_pred_svc = linear_svc.predict(X_test)\n",
    "print(\"LinearSVC:\")\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_svc))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_svc))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred_svc))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Gaussian NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes:\n",
      "Precision: 0.32266361817662187\n",
      "Recall: 0.6203296703296703\n",
      "F1-Score: 0.42451588644482047\n",
      "Accuracy: 0.6717074217074217\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB  # Import Gaussian Naive Bayes\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "# Create a Gaussian Naive Bayes classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Fit the classifier on the training data\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_gnb = gnb.predict(X_test)\n",
    "\n",
    "print(\"Gaussian Naive Bayes:\")\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_gnb))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_gnb))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred_gnb))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_gnb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classifier:\n",
      "Precision: 0.5413978494623656\n",
      "Recall: 0.5532967032967033\n",
      "F1-Score: 0.5472826086956522\n",
      "Accuracy: 0.8213213213213213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Darsh\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "# Initialize the MLPClassifier\n",
    "mlp = MLPClassifier(random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred_mlp = mlp.predict(X_test)\n",
    "print(\"MLP Classifier:\")\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_mlp))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_mlp))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred_mlp))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
