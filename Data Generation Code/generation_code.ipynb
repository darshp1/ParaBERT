{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Data Generation Code for Quora Dataset"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-10-25T18:57:55.574204Z","iopub.status.busy":"2023-10-25T18:57:55.573499Z","iopub.status.idle":"2023-10-25T18:57:56.100249Z","shell.execute_reply":"2023-10-25T18:57:56.098991Z","shell.execute_reply.started":"2023-10-25T18:57:55.574158Z"},"trusted":true},"outputs":[],"source":["# Import necessary libraries\n","import numpy as np \n","import pandas as pd \n","import os"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T18:57:56.103684Z","iopub.status.busy":"2023-10-25T18:57:56.102632Z","iopub.status.idle":"2023-10-25T18:59:14.673261Z","shell.execute_reply":"2023-10-25T18:59:14.671153Z","shell.execute_reply.started":"2023-10-25T18:57:56.103635Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pip in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (23.3.1)\n","Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (4.33.1)\n","Requirement already satisfied: sentencepiece in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.1.99)\n","Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (0.16.4)\n","Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (1.22.3)\n","Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (2023.8.8)\n","Requirement already satisfied: requests in /Users/sohamkhade/Library/Python/3.10/lib/python/site-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (0.3.3)\n","Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers) (3.3)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers) (1.26.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n","fatal: destination path 'bleurt' already exists and is not an empty directory.\n","Processing ./bleurt\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from BLEURT==0.0.2) (1.4.2)\n","Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from BLEURT==0.0.2) (1.22.3)\n","Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from BLEURT==0.0.2) (1.8.0)\n","Requirement already satisfied: tensorflow in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from BLEURT==0.0.2) (2.8.0)\n","Requirement already satisfied: tf-slim>=1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from BLEURT==0.0.2) (1.1.0)\n","Requirement already satisfied: sentencepiece in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from BLEURT==0.0.2) (0.1.99)\n","Requirement already satisfied: absl-py>=0.2.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tf-slim>=1.1->BLEURT==0.0.2) (1.0.0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas->BLEURT==0.0.2) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas->BLEURT==0.0.2) (2022.1)\n","Requirement already satisfied: astunparse>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow->BLEURT==0.0.2) (1.6.3)\n","Requirement already satisfied: flatbuffers>=1.12 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow->BLEURT==0.0.2) (2.0)\n","Requirement already satisfied: gast>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow->BLEURT==0.0.2) (0.5.3)\n","Requirement already satisfied: google-pasta>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow->BLEURT==0.0.2) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow->BLEURT==0.0.2) (3.6.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow->BLEURT==0.0.2) (1.1.2)\n","Requirement already satisfied: libclang>=9.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow->BLEURT==0.0.2) (14.0.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow->BLEURT==0.0.2) (3.3.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow->BLEURT==0.0.2) (3.20.1)\n","Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow->BLEURT==0.0.2) (58.1.0)\n","Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow->BLEURT==0.0.2) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow->BLEURT==0.0.2) (1.1.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow->BLEURT==0.0.2) (4.7.1)\n","Requirement already satisfied: wrapt>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow->BLEURT==0.0.2) (1.14.0)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow->BLEURT==0.0.2) (2.8.0)\n","Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow->BLEURT==0.0.2) (2.8.0.dev2021122109)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow->BLEURT==0.0.2) (2.8.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow->BLEURT==0.0.2) (0.25.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow->BLEURT==0.0.2) (1.44.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow->BLEURT==0.0.2) (0.37.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow->BLEURT==0.0.2) (2.6.6)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow->BLEURT==0.0.2) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow->BLEURT==0.0.2) (3.3.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /Users/sohamkhade/Library/Python/3.10/lib/python/site-packages (from tensorboard<2.9,>=2.8->tensorflow->BLEURT==0.0.2) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow->BLEURT==0.0.2) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow->BLEURT==0.0.2) (1.8.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow->BLEURT==0.0.2) (2.3.7)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->BLEURT==0.0.2) (5.0.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->BLEURT==0.0.2) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->BLEURT==0.0.2) (4.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->BLEURT==0.0.2) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->BLEURT==0.0.2) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->BLEURT==0.0.2) (3.3)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->BLEURT==0.0.2) (1.26.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->BLEURT==0.0.2) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow->BLEURT==0.0.2) (2.1.3)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->BLEURT==0.0.2) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->BLEURT==0.0.2) (3.2.0)\n","Building wheels for collected packages: BLEURT\n","  Building wheel for BLEURT (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for BLEURT: filename=BLEURT-0.0.2-py3-none-any.whl size=16456783 sha256=c777db1b7a8438669ab379d7a0ca1ade6d37248a05124784d74c9bcb629a7c66\n","  Stored in directory: /private/var/folders/f_/_d229_2x1nsg_hg3f8lpq4pw0000gn/T/pip-ephem-wheel-cache-czghm5wz/wheels/ff/db/da/7d95dfb747a2a426742968f05f5b4feebd822f680766573d19\n","Successfully built BLEURT\n","Installing collected packages: BLEURT\n","  Attempting uninstall: BLEURT\n","    Found existing installation: BLEURT 0.0.2\n","    Uninstalling BLEURT-0.0.2:\n","      Successfully uninstalled BLEURT-0.0.2\n","Successfully installed BLEURT-0.0.2\n"]}],"source":["# Ensure that pip is up-to-date by upgrading it\n","! pip install --upgrade pip  \n","# Install the 'transformers' and 'sentencepiece' packages using pip\n","! pip install transformers sentencepiece\n","# Clone the BLEURT repository from GitHub\n","! git clone https://github.com/google-research/bleurt.git\n","# Install the BLEURT package using pip\n","# This installs the BLEURT package from the local directory (./bleurt/)\n","! pip install ./bleurt/"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T18:59:14.679522Z","iopub.status.busy":"2023-10-25T18:59:14.679073Z","iopub.status.idle":"2023-10-25T19:00:02.226980Z","shell.execute_reply":"2023-10-25T19:00:02.225429Z","shell.execute_reply.started":"2023-10-25T18:59:14.679486Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py:220: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n","For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n","- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n","- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n","- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n","  warnings.warn(\n","You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Reading checkpoint bleurt-base-128.\n","INFO:tensorflow:Config file found, reading.\n","INFO:tensorflow:Will load checkpoint bert_custom\n","INFO:tensorflow:Loads full paths and checks that files exists.\n","INFO:tensorflow:... name:bert_custom\n","INFO:tensorflow:... vocab_file:vocab.txt\n","INFO:tensorflow:... bert_config_file:bert_config.json\n","INFO:tensorflow:... do_lower_case:True\n","INFO:tensorflow:... max_seq_length:128\n","INFO:tensorflow:Creating BLEURT scorer.\n","INFO:tensorflow:Creating WordPiece tokenizer.\n","INFO:tensorflow:WordPiece tokenizer instantiated.\n","INFO:tensorflow:Creating Eager Mode predictor.\n","INFO:tensorflow:Loading model.\n"]},{"name":"stderr","output_type":"stream","text":["2023-10-27 19:00:37.442457: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:BLEURT initialized.\n"]}],"source":["# Import necessary libraries\n","import csv\n","import torch\n","from transformers import T5Tokenizer, T5ForConditionalGeneration, AutoTokenizer, AutoModelForSequenceClassification\n","from bleurt.score import BleurtScorer\n","from tqdm import tqdm\n","from numpy import argmax\n","\n","# Check if a CUDA-enabled GPU is available; if yes, use it, otherwise use CPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load the T5 tokenizer from the 't5-base' pre-trained model\n","paraphrasing_tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n","\n","# Load the T5 model for conditional generation from the 'coderpotter/T5-for-Adversarial-Paraphrasing' pre-trained model\n","paraphrasing_model = T5ForConditionalGeneration.from_pretrained(\"coderpotter/T5-for-Adversarial-Paraphrasing\")\n","\n","# Set the values for various parameters\n","bleurt_threshold, initial_top_k, initial_top_p, offset_top_k, offset_top_p,  = 0.5, 120, 0.95, 20, 0.05\n","\n","# Initialize the BLEURT scorer with the 'bleurt-base-128' pre-trained model\n","bleurt_scorer = BleurtScorer(\"bleurt-base-128\")\n","\n","# Load the tokenizer for the adversarial paraphrasing detector from 'coderpotter/adversarial-paraphrasing-detector'\n","mi_tokenizer = AutoTokenizer.from_pretrained(\"coderpotter/adversarial-paraphrasing-detector\")\n","\n","# Load the pre-trained MI model for sequence classification from 'coderpotter/adversarial-paraphrasing-detector'\n","mi_model = AutoModelForSequenceClassification.from_pretrained(\"coderpotter/adversarial-paraphrasing-detector\")\n","\n","def get_mi_score(s1, s2):  # returns average of s1 and s2\n","    # Tokenize the input sequences using the mi_tokenizer\n","    tokenized_input_seq_pair = mi_tokenizer.encode_plus(s1, s2, max_length=256, return_token_type_ids=True, truncation=True)\n","    # Prepare the input tensors\n","    input_ids = torch.Tensor(tokenized_input_seq_pair[\"input_ids\"]).long().unsqueeze(0)\n","    token_type_ids = torch.Tensor(tokenized_input_seq_pair[\"token_type_ids\"]).long().unsqueeze(0)\n","    attention_mask = torch.Tensor(tokenized_input_seq_pair[\"attention_mask\"]).long().unsqueeze(0)\n","\n","    # Forward pass through the mi_model\n","    outputs = mi_model(\n","        input_ids,\n","        attention_mask=attention_mask,\n","        token_type_ids=token_type_ids,\n","        labels=None,\n","    )\n","\n","    # Obtain predicted probabilities for the first pair of sequences\n","    predicted_probability_12 = torch.softmax(outputs[0], dim=1)[0].tolist()  # batch_size only one\n","\n","    # Release memory by deleting unnecessary variables\n","    del tokenized_input_seq_pair, input_ids, token_type_ids, attention_mask, outputs\n","\n","    # Repeat the same process for the reversed order of input sequences\n","    tokenized_input_seq_pair = mi_tokenizer.encode_plus(s2, s1, max_length=256, return_token_type_ids=True, truncation=True)\n","    input_ids = torch.Tensor(tokenized_input_seq_pair[\"input_ids\"]).long().unsqueeze(0)\n","    token_type_ids = torch.Tensor(tokenized_input_seq_pair[\"token_type_ids\"]).long().unsqueeze(0)\n","    attention_mask = torch.Tensor(tokenized_input_seq_pair[\"attention_mask\"]).long().unsqueeze(0)\n","    outputs = mi_model(\n","        input_ids,\n","        attention_mask=attention_mask,\n","        token_type_ids=token_type_ids,\n","        labels=None,\n","    )\n","\n","    # Obtain predicted probabilities for the second pair of sequences\n","    predicted_probability_21 = torch.softmax(outputs[0], dim=1)[0].tolist()  # batch_size only one\n","\n","    # Release memory by deleting unnecessary variables\n","    del tokenized_input_seq_pair, input_ids, token_type_ids, attention_mask, outputs\n","\n","    # Return 1 if the first sequence is more likely related to the second sequence, 0 otherwise\n","    return int(argmax(predicted_probability_12) == 0 and argmax(predicted_probability_21) == 0)\n","\n","\n","def get_bleurt(s1, s2):\n","    # Return the computed average BLEURT score\n","    return (bleurt_scorer.score(references=[s1], candidates=[s2])[0] + bleurt_scorer.score(references=[s2], candidates=[s1])[0]) / 2\n","\n","\n","def generate_paraphrases(sentence, top_k, top_p):\n","    # Construct a text prompt for paraphrasing, including the input sentence\n","    text = \"paraphrase: \" + sentence + \" </s>\"\n","    # Encode the text prompt using the paraphrasing tokenizer\n","    encoding = paraphrasing_tokenizer.encode_plus(text, max_length=256, padding=\"max_length\", return_tensors=\"pt\")\n","    # Move the input tensors to the specified device (e.g., GPU)\n","    input_ids, attention_masks = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n","    # Generate paraphrases using the paraphrasing model\n","    beam_outputs = paraphrasing_model.generate(\n","        input_ids=input_ids,\n","        attention_mask=attention_masks,\n","        do_sample=True,\n","        max_length=256,\n","        top_k=top_k,\n","        top_p=top_p,\n","        early_stopping=True,\n","        num_return_sequences=1,\n","    )\n","    # Process and filter the generated paraphrases\n","    final_outputs = []\n","    for beam_output in beam_outputs:\n","        # Decode the generated sequence, removing special tokens and extra spaces\n","        sent = paraphrasing_tokenizer.decode(beam_output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n","        # Check if the generated paraphrase is different from the input sentence\n","        # and has not been already included in the final outputs\n","        if sent.lower() != sentence.lower() and sent not in final_outputs:\n","            final_outputs.append(sent)\n","\n","    # Return the list of filtered and unique paraphrases\n","    return final_outputs\n","\n","\n","\n","def write_paraphrases(input_file, apt_output_file, mi_output_file, nmi_output_file, position, startFrom=1, endAt=10000):  \n","    # Set initial values\n","    n, i = 4, 0\n","    written_sentences = set()\n","\n","    # Try to read previously written sentences from each output file\n","    try:\n","        with open(apt_output_file + str(i), \"r\") as f:\n","            for l in f.readlines():\n","                written_sentences.add(l.strip().split(\"\\t\")[0])\n","    except:\n","        pass\n","    try:\n","        with open(mi_output_file + str(i), \"r\") as f:\n","            for l in f.readlines():\n","                written_sentences.add(l.strip().split(\"\\t\")[0])\n","    except:\n","        pass\n","    try:\n","        with open(nmi_output_file + str(i), \"r\") as f:\n","            for l in f.readlines():\n","                written_sentences.add(l.strip().split(\"\\t\")[0])\n","    except:\n","        pass\n","\n","    # Open output files in append mode\n","    apt = open(apt_output_file, \"a+\")\n","    mi = open(mi_output_file, \"a+\")\n","    nmi = open(nmi_output_file, \"a+\")\n","\n","    # Read input CSV file\n","    with open(input_file, \"r\", encoding='utf-8') as f:\n","        reader = csv.DictReader(f, delimiter=',')\n","        # Iterate through rows with a progress bar\n","        for row in tqdm(reader, total=endAt - startFrom + 1, desc=\"Processing\"):\n","            current_id = int(row[position]) # assuming position gives the column with ID\n","            # Skip rows with ID less than startFrom\n","            if current_id < startFrom:\n","                continue\n","            # Break the loop if current_id is greater than endAt\n","            if current_id > endAt:  \n","                break\n","            sentence = row[\"question1\"]\n","            # Skip if the sentence is already written\n","            if sentence in written_sentences:\n","                continue\n","            bad_sentences, written, top_k, top_p, c = set(), False, initial_top_k, initial_top_p, 1\n","\n","            # Generate paraphrases and evaluate them\n","            for p in generate_paraphrases(sentence, top_k, top_p):\n","                if p not in bad_sentences:\n","                    bleurt, miscore = get_bleurt(sentence, p), get_mi_score(sentence, p)\n","                    # Check conditions for writing to different files\n","                    if miscore:\n","                        if bleurt < bleurt_threshold:\n","                            apt.write(sentence + \"\\t\" + p + \"\\t\" + str(bleurt) + \"\\t\" + str(miscore) + \"\\n\")\n","                            written = True\n","                        else:\n","                            bad_sentences.add(p)\n","                            mi.write(sentence + \"\\t\" + p + \"\\t\" + str(bleurt) + \"\\t\" + str(miscore) + \"\\n\")\n","                    else:\n","                        bad_sentences.add(p)\n","                        nmi.write(sentence + \"\\t\" + p + \"\\t\" + str(bleurt) + \"\\t\" + str(miscore) + \"\\n\")\n","            # Adjust parameters and try again if not written\n","            while not written and c <= 5:\n","                top_k += offset_top_k\n","                top_p -= offset_top_p\n","                for p in generate_paraphrases(sentence, top_k, top_p):\n","                    if p not in bad_sentences:\n","                        bleurt, miscore = get_bleurt(sentence, p), get_mi_score(sentence, p)\n","                        if miscore:\n","                            if bleurt < bleurt_threshold:\n","                                apt.write(sentence + \"\\t\" + p + \"\\t\" + str(bleurt) + \"\\t\" + str(miscore) + \"\\n\")\n","                                written = True\n","                            else:\n","                                bad_sentences.add(p)\n","                                mi.write(sentence + \"\\t\" + p + \"\\t\" + str(bleurt) + \"\\t\" + str(miscore) + \"\\n\")\n","                        else:\n","                            bad_sentences.add(p)\n","                            nmi.write(sentence + \"\\t\" + p + \"\\t\" + str(bleurt) + \"\\t\" + str(miscore) + \"\\n\")\n","                c += 1\n","            # Clean up variables\n","            del bad_sentences, written"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T19:00:02.234062Z","iopub.status.busy":"2023-10-25T19:00:02.230896Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing: 32010it [00:00, 164107.39it/s]          /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py:283: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n","  warnings.warn(\n","/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:399: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n","  warnings.warn(\n","Processing: 51001it [1:16:36, 11.10it/s]  \n"]}],"source":["# Set variables specific to the Quora Question Pairs dataset\n","input_file = \"Quora_QuestionPairs.csv\"  # Update this with the correct path to your dataset\n","output_file_prefix = \"data_created-1-404363/\"  # Update this as needed\n","position_of_sentence = 3  # Update this based on the position of the sentence in your dataset\n","\n","write_paraphrases(input_file, output_file_prefix + \"apt.txt\", output_file_prefix + \"mi.txt\", output_file_prefix + \"nmi.txt\", \"id\", startFrom=1, endAt=404363)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":4}
